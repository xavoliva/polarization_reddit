{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine as cosine_distance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from load.utils import load_df_from_parquet\n",
    "from preprocessing.utils import (\n",
    "    load_event_comments,\n",
    "    normalize,\n",
    ")\n",
    "from preprocessing.constants import OUTPUT_DIR\n",
    "from eda.constants import FIGURES_DIR\n",
    "from events.event_constants import EVENTS_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVENT_NAMES = [\n",
    "    # (\"gun_control\", \"mass_shootings_gun_control\"),\n",
    "    # (\"gun_control\", \"mass_shootings\"),\n",
    "    (\"elections\", \"us_elections_2012\", \"month\"),\n",
    "    (\"elections\", \"us_elections_2016\", \"week\"),\n",
    "    (\"elections\", \"us_midterms_2014\", \"month\"),\n",
    "    (\"elections\", \"us_midterms_2018\", \"week\"),\n",
    "    (\"abortion\", \"abortion\", \"month\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_theme, event_name, granularity in EVENT_NAMES:\n",
    "    print(event_theme, event_name)\n",
    "\n",
    "    print(\"Loading comments...\")\n",
    "\n",
    "    comments_with_embeddings = load_event_comments(\n",
    "        theme=event_theme,\n",
    "        event_name=event_name + \"_with_embeddings\",\n",
    "    )\n",
    "\n",
    "    # convert date to datetime\n",
    "    comments_with_embeddings[\"date\"] = pd.to_datetime(\n",
    "        comments_with_embeddings[\"created_utc\"], unit=\"s\"\n",
    "    )\n",
    "\n",
    "    comments_with_embeddings[\"week\"] = comments_with_embeddings[\"date\"].apply(\n",
    "        lambda x: x.weekofyear\n",
    "    )\n",
    "    comments_with_embeddings[\"month\"] = comments_with_embeddings[\"date\"].dt.month\n",
    "\n",
    "    print(\"Computing party probabilities...\")\n",
    "\n",
    "    probs_parties = (\n",
    "        comments_with_embeddings.groupby(by=[granularity]).apply(\n",
    "            lambda x: pd.DataFrame(\n",
    "                {\n",
    "                    \"prob_dem\": x[x[\"party\"] == \"dem\"][\"author\"].nunique()\n",
    "                    / x[\"author\"].nunique(),\n",
    "                },\n",
    "                index=[x[\"date\"].iloc[0]],\n",
    "            )\n",
    "        )\n",
    "    ).reset_index()\n",
    "\n",
    "    # join party probabilities to comments\n",
    "\n",
    "    print(\"Joining party probabilities to comments...\")\n",
    "\n",
    "    comments_with_embeddings = comments_with_embeddings.merge(\n",
    "        probs_parties,\n",
    "        on=granularity,\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    print(\"Computing user embeddings...\")\n",
    "\n",
    "    user_embeddings = (\n",
    "        comments_with_embeddings.groupby(\n",
    "            by=[pd.Grouper(key=\"date\", freq=\"W\" if granularity == \"week\" else \"M\"), \"author\", \"party\"]\n",
    "        )\n",
    "        .agg(\n",
    "            count=(\"author\", lambda x: len(x)),\n",
    "            mean=(\"embedding\", lambda x: normalize(np.vstack(x).mean(axis=0))),\n",
    "            max=(\"embedding\", lambda x: normalize(np.vstack(x).max(axis=0))),\n",
    "            random_party=(\n",
    "                \"prob_dem\",\n",
    "                lambda x: np.random.choice(\n",
    "                    [\"dem\", \"rep\"],\n",
    "                    p=[\n",
    "                        # select any value from the column\n",
    "                        x.iloc[0],\n",
    "                        1 - x.iloc[0],\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    print(user_embeddings)\n",
    "\n",
    "    # Save user embeddings\n",
    "\n",
    "    print(f\"Saving {len(user_embeddings)} user embeddings...\")\n",
    "\n",
    "    user_embeddings.to_parquet(\n",
    "        f\"{OUTPUT_DIR}/polarization/{event_theme}/{granularity}ly_{event_name}_user_embeddings.parquet\"\n",
    "    )\n",
    "\n",
    "    print(\"Computing party embeddings...\")\n",
    "\n",
    "    party_embeddings = (\n",
    "        user_embeddings.groupby(\n",
    "            by=[\n",
    "                pd.Grouper(key=\"date\", freq=\"W\" if granularity == \"week\" else \"M\"),\n",
    "                \"party\",\n",
    "            ]\n",
    "        )\n",
    "        .agg(\n",
    "            count=(\"author\", lambda x: len(x)),\n",
    "            mean=(\"mean\", lambda x: normalize(np.vstack(x).mean(axis=0))),\n",
    "            max=(\"max\", lambda x: normalize(np.vstack(x).max(axis=0))),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Save party embeddings\n",
    "\n",
    "    print(f\"Saving {len(party_embeddings)} party embeddings...\")\n",
    "\n",
    "    party_embeddings.to_parquet(\n",
    "        f\"{OUTPUT_DIR}/polarization/{event_theme}/{granularity}ly_{event_name}_party_embeddings.parquet\"\n",
    "    )\n",
    "\n",
    "    print(\"Computing CO Polarization...\")\n",
    "\n",
    "    cosine_distances = (\n",
    "        party_embeddings.groupby(by=\"date\")\n",
    "        .apply(\n",
    "            lambda x: pd.DataFrame(\n",
    "                {\n",
    "                    \"polarization_mean\": [\n",
    "                        cosine_distance(\n",
    "                            x[x[\"party\"] == \"dem\"][\"mean\"].values[0],\n",
    "                            x[x[\"party\"] == \"rep\"][\"mean\"].values[0],\n",
    "                        )\n",
    "                    ],\n",
    "                    \"polarization_max\": [\n",
    "                        cosine_distance(\n",
    "                            x[x[\"party\"] == \"dem\"][\"max\"].values[0],\n",
    "                            x[x[\"party\"] == \"rep\"][\"max\"].values[0],\n",
    "                        )\n",
    "                    ],\n",
    "                    \"count\": [x[\"count\"].sum()],\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    print(cosine_distances)\n",
    "\n",
    "    # save to parquet\n",
    "\n",
    "    print(\"Saving CO Polarization...\")\n",
    "\n",
    "    cosine_distances.to_parquet(\n",
    "        f\"{OUTPUT_DIR}/polarization/{event_theme}/{event_name}_co_polarization.parquet\"\n",
    "    )\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    print(\"Computing random party embeddings...\")\n",
    "\n",
    "    random_party_embeddings = (\n",
    "        user_embeddings.groupby(\n",
    "            by=[\n",
    "                pd.Grouper(key=\"date\", freq=\"W\" if granularity == \"week\" else \"M\"),\n",
    "                \"random_party\",\n",
    "            ]\n",
    "        )\n",
    "        .agg(\n",
    "            count=(\"author\", lambda x: len(x)),\n",
    "            mean=(\"mean\", lambda x: normalize(np.vstack(x).mean(axis=0))),\n",
    "            max=(\"max\", lambda x: normalize(np.vstack(x).max(axis=0))),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Save party embeddings\n",
    "\n",
    "    print(f\"Saving {len(random_party_embeddings)} party embeddings...\")\n",
    "\n",
    "    print(\"Computing random CO Polarization...\")\n",
    "\n",
    "    random_cosine_distances = (\n",
    "        random_party_embeddings.groupby(by=\"date\")\n",
    "        .apply(\n",
    "            lambda x: pd.DataFrame(\n",
    "                {\n",
    "                    \"polarization_mean\": [\n",
    "                        cosine_distance(\n",
    "                            x[x[\"random_party\"] == \"dem\"][\"mean\"].values[0],\n",
    "                            x[x[\"random_party\"] == \"rep\"][\"mean\"].values[0],\n",
    "                        )\n",
    "                    ],\n",
    "                    \"polarization_max\": [\n",
    "                        cosine_distance(\n",
    "                            x[x[\"random_party\"] == \"dem\"][\"max\"].values[0],\n",
    "                            x[x[\"random_party\"] == \"rep\"][\"max\"].values[0],\n",
    "                        )\n",
    "                    ],\n",
    "                    \"count\": [x[\"count\"].sum()],\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    print(random_cosine_distances)\n",
    "\n",
    "    # save to parquet\n",
    "\n",
    "    print(\"Saving random CO Polarization...\")\n",
    "\n",
    "    random_cosine_distances.to_parquet(\n",
    "        f\"{OUTPUT_DIR}/polarization/{event_theme}/random_{event_name}_co_polarization.parquet\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_theme, event_name, granularity in EVENT_NAMES:\n",
    "    print(event_theme, event_name)\n",
    "\n",
    "    # Load LO polarization\n",
    "    lo_pol_by_time_events = pd.read_parquet(\n",
    "        f\"{OUTPUT_DIR}/{event_name}_leaveout_polarization_by_{granularity}.parquet\",\n",
    "    )\n",
    "\n",
    "    lo_pol_by_time_events[\"date\"] = pd.to_datetime(lo_pol_by_time_events[\"date\"])\n",
    "\n",
    "    # Load CO Polarization\n",
    "\n",
    "    cosine_distances = pd.read_parquet(\n",
    "        f\"{OUTPUT_DIR}/polarization/{event_theme}/{event_name}_co_polarization.parquet\"\n",
    "    )\n",
    "    cosine_distances = cosine_distances[cosine_distances[\"count\"] > 500]\n",
    "\n",
    "    # Load random CO Polarization\n",
    "\n",
    "    random_cosine_distances = pd.read_parquet(\n",
    "        f\"{OUTPUT_DIR}/polarization/{event_theme}/random_{event_name}_co_polarization.parquet\"\n",
    "    )\n",
    "\n",
    "    random_cosine_distances = random_cosine_distances[\n",
    "        random_cosine_distances[\"count\"] > 500\n",
    "    ]\n",
    "\n",
    "    # plot polarization_mean by date\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    ax = sns.lineplot(\n",
    "        x=cosine_distances[\"date\"],\n",
    "        y=cosine_distances[\"polarization_mean\"],\n",
    "        label=\"Contextualized estimator\",\n",
    "        marker=\"o\",\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "    _ = sns.lineplot(\n",
    "        x=random_cosine_distances[\"date\"],\n",
    "        y=random_cosine_distances[\"polarization_mean\"],\n",
    "        label=\"Contextualized estimator with random party assignment\",\n",
    "        marker=\"o\",\n",
    "        color=\"orange\",\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax2 = plt.twinx()\n",
    "    sns.lineplot(\n",
    "        x=lo_pol_by_time_events[\"date\"],\n",
    "        y=lo_pol_by_time_events[\"polarization\"],\n",
    "        label=\"Leave-out estimator\",\n",
    "        marker=\"o\",\n",
    "        color=\"blue\",\n",
    "        linestyle=\"--\",\n",
    "        ax=ax2,\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    event_details = EVENTS_INFO[event_name]\n",
    "\n",
    "    trans = ax.get_xaxis_transform()\n",
    "\n",
    "    if \"date\" in event_details:\n",
    "        plt.axvline(\n",
    "            event_details[\"date\"],\n",
    "            linestyle=\"--\",\n",
    "            color=\"red\",\n",
    "            # label=f\"{event_details['name']}\",  #  ({date_str})\n",
    "        )\n",
    "        plt.text(\n",
    "            event_details[\"date\"],\n",
    "            0.1,\n",
    "            event_details['name'],\n",
    "            fontsize='x-small',\n",
    "            transform=trans,\n",
    "            rotation=-90,\n",
    "        )\n",
    "\n",
    "\n",
    "    for relevant_event, relevant_event_date in event_details[\"relevant_dates\"].items():\n",
    "        # date_str = relevant_event_date.strftime(\"%Y-%m-%d\")\n",
    "        plt.axvline(\n",
    "            relevant_event_date,\n",
    "            linestyle=\"--\",\n",
    "            color=\"blue\",\n",
    "            # label=f\"{relevant_event}\", #  ({date_str})\n",
    "        )\n",
    "\n",
    "        plt.text(\n",
    "            relevant_event_date,\n",
    "            0.1,\n",
    "            relevant_event,\n",
    "            fontsize='x-small',\n",
    "            transform=trans,\n",
    "            rotation=-90,\n",
    "        )\n",
    "\n",
    "    ax.set(\n",
    "        xlabel=\"Date\",\n",
    "        ylabel=\"Contextualized partisanship score estimate\",\n",
    "    )\n",
    "\n",
    "    ax2.set(\n",
    "        xlabel=\"Date\",\n",
    "        ylabel=\"Leave-out partisanship score estimate\",\n",
    "    )\n",
    "\n",
    "    plt.savefig(\n",
    "        fname=f\"{FIGURES_DIR}/polarization/{event_name}/{event_name}_co_polarization.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pol_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
