{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "#     handlers=[\n",
    "#         logging.FileHandler(\"data/logs/preprocess_comments_notebook.log\"),\n",
    "#         logging.StreamHandler()\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from load.utils import (\n",
    "    load_users,\n",
    "    load_subreddits,\n",
    "    load_user_party,\n",
    "    load_comments,\n",
    "    save_df_as_parquet,\n",
    ")\n",
    "from preprocessing.utils import (\n",
    "    tokenize_comment,\n",
    "    calculate_user_party,\n",
    "    save_event_comments,\n",
    "    build_vocab,\n",
    "    save_event_vocab,\n",
    ")\n",
    "\n",
    "from preprocessing.constants import (\n",
    "    METADATA_DIR,\n",
    "    ELECTIONS_EVENTS_INFO,\n",
    "    MIN_OCCURENCE_FOR_VOCAB,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2008\n",
    "START_MONTH = 1\n",
    "STOP_MONTH = 12\n",
    "\n",
    "EVENT_NAME = f\"us_elections_{YEAR}\"\n",
    "EVENT_INFO = ELECTIONS_EVENTS_INFO[EVENT_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = load_subreddits()\n",
    "\n",
    "logging.info(subreddits.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take into account network structure to find other partisan subreddits which are not labeled\n",
    "dem_subreddits = set(\n",
    "    json.load(\n",
    "        open(\n",
    "            f\"{METADATA_DIR}/dem_subreddits_{YEAR}_unweighted.json\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "rep_subreddits = set(\n",
    "    json.load(\n",
    "        open(\n",
    "            f\"{METADATA_DIR}/rep_subreddits_{YEAR}_unweighted.json\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "partisan_subreddits = dem_subreddits | rep_subreddits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter partisan subreddits\n",
    "# subreddits = subreddits[subreddits[\"party\"].isin({\"dem\", \"rep\"})]\n",
    "subreddits = subreddits.query(\"subreddit in @partisan_subreddits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(subreddits.groupby(\"party\")[\"subreddit\"].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Load comments...\")\n",
    "\n",
    "comments_pl = load_comments(\n",
    "    year=YEAR,\n",
    "    start_month=START_MONTH,\n",
    "    stop_month=STOP_MONTH,\n",
    "    engine=\"polars\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_comments_pl = comments_pl.filter(pl.col(\"subreddit\").is_in(list(partisan_subreddits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_comments = partisan_comments_pl.to_pandas(\n",
    "    # use_pyarrow_extension_array=True,\n",
    ").astype(\n",
    "    {\n",
    "        \"author\": \"string[pyarrow]\",\n",
    "        \"body_cleaned\": \"string[pyarrow]\",\n",
    "        \"created_utc\": \"int64[pyarrow]\",\n",
    "        \"subreddit\": \"string[pyarrow]\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partisan_comments = comments.query(\"subreddit in @partisan_subreddits\").copy()\n",
    "# partisan_comments = comments.loc[t] # .copy()\n",
    "\n",
    "logging.info(partisan_comments.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Add party information to comments...\")\n",
    "\n",
    "partisan_comments[\"party\"] = np.where(\n",
    "    partisan_comments[\"subreddit\"].isin(dem_subreddits), \"dem\", \"rep\"\n",
    ")\n",
    "partisan_comments[\"party\"] = partisan_comments[\"party\"].astype(\"string[pyarrow]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(partisan_comments.shape)\n",
    "\n",
    "save_df_as_parquet(\n",
    "    partisan_comments,\n",
    "    target_file=f\"partisan_comments_{YEAR}.parquet\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_party = partisan_comments.groupby(by=\"author\").progress_apply(\n",
    "    calculate_user_party,\n",
    ")\n",
    "user_party = user_party[user_party[\"score\"] != 0].reset_index().copy()\n",
    "user_party[\"party\"] = user_party[\"party\"].astype(\"string[pyarrow]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_party.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Nr of users: {len(user_party)}\")\n",
    "\n",
    "logging.info(user_party.groupby(by=\"party\")[\"author\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_parquet(\n",
    "    data=user_party,\n",
    "    target_file=f\"user_party_{YEAR}.parquet\",\n",
    ")\n",
    "\n",
    "logging.info(user_party.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter event comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info(\"Load user party\")\n",
    "# user_party = load_user_party(year=YEAR)\n",
    "\n",
    "logging.info(user_party.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(partisan_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = load_users(engine=\"polars\")\n",
    "\n",
    "logging.info(users.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Filter out bots & automoderators comments...\")\n",
    "partisan_comments = partisan_comments.merge(\n",
    "    users,\n",
    "    on=\"author\",\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(partisan_comments.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Filtering event data based on keywords...\")\n",
    "event_comments = partisan_comments[\n",
    "    partisan_comments[\"body_cleaned\"].str.contains(\n",
    "        EVENT_INFO[\"regex\"],\n",
    "        regex=True,\n",
    "    )\n",
    "].copy()\n",
    "logging.info(\"finished keyword filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(event_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"save temp event comments\")\n",
    "save_event_comments(event_comments, f\"temp_{EVENT_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_party\n",
    "del users\n",
    "del subreddits\n",
    "del comments_pl\n",
    "del partisan_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(event_comments.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and stem comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Tokenizing comments...\")\n",
    "event_comments[\"tokens\"] = event_comments[\"body_cleaned\"].progress_apply(\n",
    "    tokenize_comment,\n",
    ").astype(\"string[pyarrow]\")\n",
    "logging.info(\"Finish tokenizing comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(event_comments.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Nr of event comments: {len(event_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"saving event comments...\")\n",
    "save_event_comments(event_comments, EVENT_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build event vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read event data\n",
    "# events_comments = load_event_comments(\n",
    "#     event_comments,\n",
    "#     EVENT_NAME,\n",
    "#     file_type=\"parquet\",\n",
    "# )\n",
    "\n",
    "event_vocab = build_vocab(\n",
    "    event_comments[\"tokens\"],\n",
    "    min_comment_freq=MIN_OCCURENCE_FOR_VOCAB,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Vocabulary length\")\n",
    "logging.info(len(event_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Saving event vocab\")\n",
    "save_event_vocab(event_vocab, EVENT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pol_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0517ac6396832503edeb22d4ae2d55ad6af9f111efda9985705546d6640f6543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
