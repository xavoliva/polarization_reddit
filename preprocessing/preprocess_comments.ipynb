{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     level=logging.INFO,\n",
    "#     format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "#     handlers=[\n",
    "#         logging.FileHandler(\"data/logs/preprocess_comments_notebook.log\"),\n",
    "#         logging.StreamHandler()\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from load.utils import (\n",
    "    load_users,\n",
    "    load_subreddits,\n",
    "    load_user_party,\n",
    "    load_comments,\n",
    "    save_df_as_parquet,\n",
    ")\n",
    "from preprocessing.utils import (\n",
    "    tokenize_comment,\n",
    "    calculate_user_party,\n",
    "    save_event_comments,\n",
    "    build_vocab,\n",
    "    save_event_vocab,\n",
    ")\n",
    "\n",
    "from preprocessing.constants import (\n",
    "    METADATA_DIR,\n",
    "    ELECTIONS_REGEX,\n",
    "    MIN_OCCURENCE_FOR_VOCAB,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2008\n",
    "START_MONTH = 1\n",
    "STOP_MONTH = 12\n",
    "\n",
    "EVENT_NAME = f\"us_elections_{YEAR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = load_subreddits()\n",
    "\n",
    "logging.info(subreddits.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dss/dsshome1/03/di93fup/polarization_reddit/data/metadata/dem_subreddits_2008_unweighted.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# take into account network structure to find other partisan subreddits which are not labeled\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dem_subreddits \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m      3\u001b[0m     json\u001b[39m.\u001b[39mload(\n\u001b[0;32m----> 4\u001b[0m         \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m      5\u001b[0m             \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mMETADATA_DIR\u001b[39m}\u001b[39;49;00m\u001b[39m/dem_subreddits_\u001b[39;49m\u001b[39m{\u001b[39;49;00mYEAR\u001b[39m}\u001b[39;49;00m\u001b[39m_unweighted.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m         )\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m rep_subreddits \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m     10\u001b[0m     json\u001b[39m.\u001b[39mload(\n\u001b[1;32m     11\u001b[0m         \u001b[39mopen\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m partisan_subreddits \u001b[39m=\u001b[39m dem_subreddits \u001b[39m|\u001b[39m rep_subreddits\n",
      "File \u001b[0;32m~/.conda/envs/pol_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dss/dsshome1/03/di93fup/polarization_reddit/data/metadata/dem_subreddits_2008_unweighted.json'"
     ]
    }
   ],
   "source": [
    "# take into account network structure to find other partisan subreddits which are not labeled\n",
    "dem_subreddits = set(\n",
    "    json.load(\n",
    "        open(\n",
    "            f\"{METADATA_DIR}/dem_subreddits_{YEAR}_unweighted.json\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "rep_subreddits = set(\n",
    "    json.load(\n",
    "        open(\n",
    "            f\"{METADATA_DIR}/rep_subreddits_{YEAR}_unweighted.json\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "partisan_subreddits = dem_subreddits | rep_subreddits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter partisan subreddits\n",
    "# subreddits = subreddits[subreddits[\"party\"].isin({\"dem\", \"rep\"})]\n",
    "subreddits = subreddits.query(\"subreddit in @partisan_subreddits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(subreddits.groupby(\"party\")[\"subreddit\"].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Load comments...\")\n",
    "\n",
    "comments_pl = load_comments(\n",
    "    year=YEAR,\n",
    "    start_month=START_MONTH,\n",
    "    stop_month=STOP_MONTH,\n",
    "    engine=\"polars\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_comments_pl = comments_pl.filter(pl.col(\"subreddit\").is_in(list(partisan_subreddits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partisan_comments = partisan_comments_pl.to_pandas(\n",
    "    # use_pyarrow_extension_array=True,\n",
    ").astype(\n",
    "    {\n",
    "        \"author\": \"string[pyarrow]\",\n",
    "        \"body_cleaned\": \"string[pyarrow]\",\n",
    "        \"created_utc\": \"int64[pyarrow]\",\n",
    "        \"subreddit\": \"string[pyarrow]\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          string[pyarrow]\n",
       "body_cleaned    string[pyarrow]\n",
       "created_utc      int64[pyarrow]\n",
       "subreddit       string[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partisan_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partisan_comments = comments.query(\"subreddit in @partisan_subreddits\").copy()\n",
    "# partisan_comments = comments.loc[t] # .copy()\n",
    "\n",
    "logging.info(partisan_comments.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Add party information to comments...\")\n",
    "\n",
    "partisan_comments[\"party\"] = np.where(\n",
    "    partisan_comments[\"subreddit\"].isin(dem_subreddits), \"dem\", \"rep\"\n",
    ")\n",
    "partisan_comments[\"party\"] = partisan_comments[\"party\"].astype(\"string[pyarrow]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          string[pyarrow]\n",
       "body_cleaned    string[pyarrow]\n",
       "created_utc      int64[pyarrow]\n",
       "subreddit       string[pyarrow]\n",
       "party           string[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partisan_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(partisan_comments.shape)\n",
    "\n",
    "save_df_as_parquet(\n",
    "    partisan_comments,\n",
    "    target_file=f\"partisan_comments_{YEAR}.parquet\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33666/33666 [00:48<00:00, 688.11it/s]\n"
     ]
    }
   ],
   "source": [
    "user_party = partisan_comments.groupby(by=\"author\").progress_apply(\n",
    "    calculate_user_party,\n",
    ")\n",
    "user_party = user_party[user_party[\"score\"] != 0].reset_index().copy()\n",
    "user_party[\"party\"] = user_party[\"party\"].astype(\"string[pyarrow]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author     string[pyarrow]\n",
       "dem_cnt              int64\n",
       "rep_cnt              int64\n",
       "score                int64\n",
       "party      string[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_party.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Nr of users: {len(user_party)}\")\n",
    "\n",
    "logging.info(user_party.groupby(by=\"party\")[\"author\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_parquet(\n",
    "    data=user_party,\n",
    "    target_file=f\"user_party_{YEAR}.parquet\",\n",
    ")\n",
    "\n",
    "logging.info(user_party.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter event comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info(\"Load user party\")\n",
    "# user_party = load_user_party(year=YEAR)\n",
    "\n",
    "logging.info(user_party.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(partisan_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = load_users(engine=\"polars\")\n",
    "\n",
    "logging.info(users.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Filter out bots & automoderators comments...\")\n",
    "partisan_comments = partisan_comments.merge(\n",
    "    users,\n",
    "    on=\"author\",\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(partisan_comments.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Filtering event data based on keywords...\")\n",
    "event_comments = partisan_comments[\n",
    "    partisan_comments[\"body_cleaned\"].str.contains(\n",
    "        ELECTIONS_REGEX[YEAR],\n",
    "        regex=True,\n",
    "    )\n",
    "].copy()\n",
    "logging.info(\"finished keyword filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(event_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"save temp event comments\")\n",
    "save_event_comments(event_comments, f\"temp_{EVENT_NAME}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del user_party\n",
    "del users\n",
    "del subreddits\n",
    "del comments_pl\n",
    "del partisan_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(event_comments.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and stem comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128307/128307 [02:54<00:00, 736.56it/s] \n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Tokenizing comments...\")\n",
    "event_comments[\"tokens\"] = event_comments[\"body_cleaned\"].progress_apply(\n",
    "    tokenize_comment,\n",
    ").astype(\"string[pyarrow]\")\n",
    "logging.info(\"Finish tokenizing comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(event_comments.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Nr of event comments: {len(event_comments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"saving event comments...\")\n",
    "save_event_comments(event_comments, EVENT_NAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build event vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read event data\n",
    "# events_comments = load_event_comments(\n",
    "#     event_comments,\n",
    "#     EVENT_NAME,\n",
    "#     file_type=\"parquet\",\n",
    "# )\n",
    "\n",
    "event_vocab = build_vocab(\n",
    "    event_comments[\"tokens\"],\n",
    "    min_comment_freq=MIN_OCCURENCE_FOR_VOCAB,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Vocabulary length\")\n",
    "logging.info(len(event_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Saving event vocab\")\n",
    "save_event_vocab(event_vocab, EVENT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pol_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 (default, Jan 17 2023, 23:13:24) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0517ac6396832503edeb22d4ae2d55ad6af9f111efda9985705546d6640f6543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
